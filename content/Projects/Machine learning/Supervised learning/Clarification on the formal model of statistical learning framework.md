The general problem stated in [[Projects/Machine learning/Supervised learning/A Formal Model – The Statistical Learning Framework|A Formal Model – The Statistical Learning Framework]] needs some important clarification in order to not incur in typical mistakes.
#### How the training set is generated

Given a domain set $X$, when we sample an element from it we must assume that there is an underlying probability distribution from which is generated. We call this distribution $D$.
**Note that the learner doesn't know anything about this distribution**. If it does then it should be able of making predictions using the distribution making the learning approach useless.
	Suppose for instance in the papaya example that we know that all the features distributes according to a Gaussian distribution. Then one would naturally choose the mean for each feature as a predictor of tastiness. In this approach no papaya will be tasted.
As to the labels, in the current discussion we assume that there is some “correct” labeling function $f:X\to Y$ such that $y_i = f(x_i)\quad \forall (x_i,y_i)\in S$.
Note that **the labeling function is unknown to the learner** . In fact, this is just what the learner is trying to figure out.
In summary, each pair in the training data $S$ is generated by first sampling a point $x_i$ according to $D$ and then labeling it by $f$ (i.e. we are assuming correct labeling )

#### How can we measure the error of a prediction

We define the error of a classifier to be the probability that it does not predict the correct label on a random data point generated by the aforementioned underlying distribution.
The error is defined in the following way:

$$ L_{D,f}(h) = \mathbb{P}(h(x)\neq f(x)) = D(x:h(x)\neq f(x)) $$

Simply speaking the error is defined as the probability that our hypothesis label is different from the true label for a generic $x \in X$. 
Notice that the condition $h(x)\neq f(x)$ implicitly defines a subset $A \subset X$, i.e. $A = \{ x \in X : h(x)\neq f(x) \}$.
Now we explain how the last number can be evaluated for a generic subset.

This can be done in the following way: given a domain subset $A \subset X$, the probability distribution $D$ assigns a number that we call $D(A)=D(x:x \in A)$ which determines how likely it is to observe a point $x \in A$, in other another way, supposing for example that $D$ is a continuous distribution $D(A)=\int_A D(x)dx= \mathbb{P}_{x \sim D}\{x |x \in A\}$.
**Notice that we know anything about the distribution**, this number is just given to us by counting.
	 This is simply given by sampled point that lies in A over total sampled points.
Another formal way to write the probability is to use an indicator function. Suppose for example to have an unknown distribution function with sample space $\mathbb{R}$. Then: $\mathbb{P}_{x \sim D}\{x |x \in A\}=\int_A D(x)dx= \int_{\mathbb{R}}\mathbb{1}_A D(x)dx= \mathbb{P}_{x \sim D}\{x |\mathbb{1}_A(x)=1\}$
